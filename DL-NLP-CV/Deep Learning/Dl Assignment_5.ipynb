{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6bd03c",
   "metadata": {},
   "source": [
    "# Solution Assignment : 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a248256",
   "metadata": {},
   "source": [
    "#### 1.\tWhy would you want to use the Data API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077e760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f184",
   "metadata": {},
   "source": [
    "#### 2.\tWhat are the benefits of splitting a large dataset into multiple files?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1408b77",
   "metadata": {},
   "source": [
    "Benefits to splitting a large dataset into multiple files. These include:\n",
    "\n",
    "Improved performance: Splitting a large dataset into multiple files can improve the performance of machine learning models by making it easier to load and process the data. This is because each file can be loaded and processed independently, which can reduce the amount of time it takes to load and process the entire dataset.\n",
    "Increased scalability: Splitting a large dataset into multiple files can make it easier to scale machine learning models to handle larger datasets. This is because each file can be processed independently, which means that the model can be scaled by simply adding more machines to process the files in parallel.\n",
    "Enhanced fault tolerance: Splitting a large dataset into multiple files can enhance the fault tolerance of machine learning models. This is because if one file is corrupted or unavailable, the model can still be trained and tested using the remaining files.\n",
    "Simplified data management: Splitting a large dataset into multiple files can simplify the data management process. This is because each file can be stored and managed independently, which makes it easier to track and access the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7aaa4",
   "metadata": {},
   "source": [
    "#### 3.\tDuring training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0a3b1",
   "metadata": {},
   "source": [
    "Ways to understand if input pipeline is the bottleneck during training. These include:\n",
    "\n",
    "The time it takes to load a batch of data. If the time it takes to load a batch of data is significantly longer than the time it takes to train the model on the data, then your input pipeline is likely the bottleneck.\n",
    "The CPU utilization. If the CPU utilization is high during training, but the GPU utilization is low, then your input pipeline is likely the bottleneck.\n",
    "The TensorFlow Profiler. The TensorFlow Profiler can be used to identify the bottlenecks in your TensorFlow program. If the Profiler shows that the input pipeline is the bottleneck, then you can take steps to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cb7cc",
   "metadata": {},
   "source": [
    "#### 4.\tCan you save any binary data to a TFRecord file, or only serialized protocol buffers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9201e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "332cbd41",
   "metadata": {},
   "source": [
    "#### 5.\tWhy would you go through the hassle of converting all your data to the Example protobuf format? Why not use your own protobuf definition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d9a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e479268",
   "metadata": {},
   "source": [
    "#### 6.\tWhen using TFRecords, when would you want to activate compression? Why not do it systematically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079e707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71bd58a",
   "metadata": {},
   "source": [
    "#### 7.\tData can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model, or using TF Transform. Can you list a few pros and cons of each option?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66c4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
