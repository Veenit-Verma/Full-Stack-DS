{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6bd03c",
   "metadata": {},
   "source": [
    "# Solution Assignment : 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a248256",
   "metadata": {},
   "source": [
    "#### 1.\tWhat are the advantages of a CNN over a fully connected DNN for image classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11ad6f",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) have several advantages over fully connected DNNs for image classification, including:\n",
    "\n",
    "Sparsity of connections: CNNs have sparse connections between layers, which means that each neuron in a layer only receives input from a small number of neurons in the previous layer. This makes CNNs more efficient to train and reduces the risk of overfitting.\n",
    "Locality: CNNs are able to learn local features in images, such as edges and shapes. This is because the convolution operation only considers a small region of the input image at a time. This makes CNNs more robust to changes in the global appearance of an image.\n",
    "Translation invariance: CNNs are invariant to translations of the input image. This means that they can still classify an image correctly even if it is shifted or rotated. This is because the convolution operation is performed over a sliding window, which means that the same features are extracted regardless of the position of the window in the image.\n",
    "Feature extraction: CNNs can automatically learn features from images without the need for manual feature engineering. This is a major advantage, as manual feature engineering can be time-consuming and error-prone.\n",
    "As a result of these advantages, CNNs have become the state-of-the-art for image classification tasks. They have achieved state-of-the-art results on a variety of image classification benchmarks, including ImageNet, CIFAR-10, and MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f184",
   "metadata": {},
   "source": [
    "#### 2.\tConsider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad0da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edf7aaa4",
   "metadata": {},
   "source": [
    "#### 3.\tIf your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641c405",
   "metadata": {},
   "source": [
    "Reduce the mini-batch size.\n",
    "Reduce dimensionality using a larger stride in one or more layers.\n",
    "Remove one or more layers.\n",
    "Use 16-bit floats instead of 32-bit floats.\n",
    "Distribute the CNN across multiple devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cb7cc",
   "metadata": {},
   "source": [
    "#### 4.\tWhy would you want to add a max pooling layer rather than a convolutional layer with the same stride?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8076e",
   "metadata": {},
   "source": [
    "A max pooling layer has no parameters at all, whereas a convolutional layer has a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cbd41",
   "metadata": {},
   "source": [
    "#### 5.\tWhen would you want to add a local response normalization layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843af078",
   "metadata": {},
   "source": [
    "This form of normalization makes the neurons that most strongly activate inhibit neurons at the same location but in neighboring feature maps (such competitive activation has been observed in biological neurons). This encourages different feature maps to specialize, pushing them apart and forcing them to explore a wider range of features, ultimately improving generalization.\n",
    "It is typically used in the lower layers to have a larger pool of low-level features that the upper layers can build upon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e479268",
   "metadata": {},
   "source": [
    "#### 6.\tCan you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f273898",
   "metadata": {},
   "source": [
    "The main innovations in AlexNet compared to LeNet-5 are (1) it is much larger and deeper, and (2) it stacks convolutional layers directly on top of each other, instead of stacking a pooling layer on top of each convolutional layer.\n",
    "The main innovation in GoogLeNet is the introduction of inception modules, which make it possible to have a much deeper net than previous CNN architectures, with fewer parameters.\n",
    "Finally, ResNet's main innovation is the introduction of skip connections, which make it possible to go well beyond 100 layers. Arguably, its simplicity and consistency are also rather innovative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71bd58a",
   "metadata": {},
   "source": [
    "#### 7.\tWhat is a fully convolutional network? How can you convert a dense layer into a convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d3dd6",
   "metadata": {},
   "source": [
    "A fully convolutional network (FCN) is a type of convolutional neural network (CNN) that does not contain any fully connected layers. Instead, it uses only convolutional and pooling layers. This makes FCNs well-suited for image segmentation tasks, where the goal is to predict a label for each pixel in an image.\n",
    "\n",
    "To convert a dense layer into a convolutional layer, you can use a 1x1 convolution. A 1x1 convolution is a convolution operation that has a kernel size of 1x1. This means that the convolution operation only considers the immediate neighbors of each pixel. This makes 1x1 convolutions very efficient, and they can be used to replace fully connected layers in CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16db75",
   "metadata": {},
   "source": [
    "#### 8.\tWhat is the main technical difficulty of semantic segmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc3016",
   "metadata": {},
   "source": [
    "The main technical difficulty of semantic segmentation is the loss of spatial information during the downsampling process. This is because convolutional neural networks (CNNs) use pooling layers to reduce the size of the feature maps. This can be helpful for reducing the computational complexity of the model, but it also results in the loss of some spatial information. This can make it difficult for the model to accurately predict the boundaries between different objects in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e3af2",
   "metadata": {},
   "source": [
    "#### 9.\tBuild your own CNN from scratch and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c6a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd77bd31",
   "metadata": {},
   "source": [
    "#### 10.\tUse transfer learning for large image classification, going through these steps:\n",
    "- a.\tCreate a training set containing at least 100 images per class. For example, you could classify your own pictures based on the location (beach, mountain, city, etc.), or alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "- b.\tSplit it into a training set, a validation set, and a test set.\n",
    "- c.\tBuild the input pipeline, including the appropriate preprocessing operations, and optionally add data augmentation.\n",
    "- d.\tFine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743683d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
